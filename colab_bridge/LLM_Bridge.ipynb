{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36c86855",
      "metadata": {
        "id": "36c86855"
      },
      "source": [
        "# üé≠ AI Companion: Universal Roleplay Bridge (Threaded)\n",
        "\n",
        "**FIXED:** This version runs the server in a background thread to avoid Colab event loop conflicts.\n",
        "\n",
        "### Instructions:\n",
        "1. **Runtime:** `Runtime` > `Change runtime type` > **T4 GPU**.\n",
        "2. **Ngrok:** Paste your token in Cell 3.\n",
        "3. **Run All:** Press `Ctrl + F9`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "lBKcj3C9x2bk",
      "metadata": {
        "id": "lBKcj3C9x2bk"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "892384df",
      "metadata": {
        "id": "892384df"
      },
      "outputs": [],
      "source": [
        "# @title 1. Install Dependencies\n",
        "!pip install -q -U fastapi uvicorn pyngrok nest_asyncio requests==2.32.4\n",
        "!pip install -q -U transformers accelerate bitsandbytes torch==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "488f0dcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "282fe5a457b94d10b573ea61f615fe4e",
            "fbb6e4f7d924442682724d44c8ec91e7",
            "9316dd5f09904484bbcbe7d0e9a11930",
            "22de08480694474fa057c2eb72ac52c8",
            "357a48fc1e024da59acfe3f9f94676d2",
            "f932540ac5e4434191ba0cb2faa9867e",
            "fb4d9022f03944e191c3108215528152",
            "6409120291aa4784825078d3ee97dfd5",
            "3f63188b8bdc40049976397b867e6782",
            "bff783756fd4420aa0c84d30048c9e90",
            "29ebb73be9a84e46aa2738e4a1a80f7a"
          ]
        },
        "id": "488f0dcc",
        "outputId": "6802cc24-e8b7-4090-8bda-47756fbcc363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Sao10K/L3-8B-Stheno-v3.2...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "282fe5a457b94d10b573ea61f615fe4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Roleplay Specialist LOADED on Tesla T4!\n"
          ]
        }
      ],
      "source": [
        "# @title 2. Load Roleplay Specialist (Stheno-v3.2)\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer, BitsAndBytesConfig\n",
        "from threading import Thread\n",
        "\n",
        "# --- AUTH ---\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "# ------------\n",
        "\n",
        "model_id = \"Sao10K/L3-8B-Stheno-v3.2\"\n",
        "\n",
        "print(f\"Loading {model_id}...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Roleplay Specialist LOADED on {torch.cuda.get_device_name(0)}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11fdc1a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11fdc1a5",
        "outputId": "66e2fda2-1911-4034-abe7-78e607ae210d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "\n",
            "üöÄ BRIDGE ONLINE!\n",
            "URL: https://aerobically-meddlesome-ria.ngrok-free.dev\n",
            "\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-6 (generate):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\", line 275, in __getattr__\n",
            "    return self.data[item]\n",
            "           ~~~~~~~~~^^^^^^\n",
            "KeyError: 'shape'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\", line 2504, in generate\n",
            "    batch_size = inputs_tensor.shape[0]\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\", line 277, in __getattr__\n",
            "    raise AttributeError\n",
            "AttributeError\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stopping server...\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.responses import StreamingResponse\n",
        "import uvicorn, nest_asyncio, re, os, time, random\n",
        "from pyngrok import ngrok\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "from threading import Thread\n",
        "from transformers import TextIteratorStreamer\n",
        "\n",
        "NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class Message(BaseModel):\n",
        "    role: str\n",
        "    content: str\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    messages: List[Message]\n",
        "    max_tokens: int = 1024\n",
        "    temperature: float = 0.8\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat_endpoint(request: ChatRequest):\n",
        "    chat = [{\"role\": m.role, \"content\": m.content} for m in request.messages]\n",
        "\n",
        "    # We use return_dict=True to get a dictionary of tensors (input_ids, attention_mask)\n",
        "    # Then we unpack it into generation_kwargs to avoid BatchEncoding attribute errors.\n",
        "    model_inputs = tokenizer.apply_chat_template(\n",
        "        chat,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True\n",
        "    ).to(model.device)\n",
        "\n",
        "    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "    generation_kwargs = {\n",
        "        **model_inputs,\n",
        "        \"streamer\": streamer,\n",
        "        \"max_new_tokens\": request.max_tokens,\n",
        "        \"temperature\": request.temperature,\n",
        "        \"do_sample\": True,\n",
        "        \"top_p\": 0.9,\n",
        "    }\n",
        "\n",
        "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "    thread.start()\n",
        "\n",
        "    def stream_generator():\n",
        "        for new_text in streamer:\n",
        "            yield new_text\n",
        "\n",
        "    return StreamingResponse(stream_generator(), media_type=\"text/plain\")\n",
        "\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# Ensure all existing ngrok tunnels are killed before starting a new one\n",
        "ngrok.kill()\n",
        "\n",
        "try:\n",
        "    for tunnel in ngrok.get_tunnels():\n",
        "        ngrok.disconnect(tunnel.public_url)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"error\")\n",
        "\n",
        "server_thread = Thread(target=run_server)\n",
        "server_thread.daemon = True # Allows the main program to exit even if this thread is still running\n",
        "server_thread.start()\n",
        "\n",
        "# Give the server a moment to start and bind or fail.\n",
        "time.sleep(1)\n",
        "\n",
        "if not server_thread.is_alive():\n",
        "    # If the thread is not alive after a short delay, it likely failed to start\n",
        "    print(\"\\n\\n--------------------------------------------------\")\n",
        "    print(\"‚ùå ERROR: FastAPI server failed to start!\")\n",
        "    print(\"This is likely due to port 8000 already in use.\")\n",
        "    print(\"Please try one of the following:\")\n",
        "    print(\"1. Restart the Colab runtime (Runtime > Restart runtime).\")\n",
        "    print(\"2. If you ran this cell multiple times, wait a few seconds and try again.\")\n",
        "    print(\"--------------------------------------------------\\n\\n\")\n",
        "else:\n",
        "    # If the server thread is alive, assume it started successfully, then connect ngrok\n",
        "    try:\n",
        "        public_url = ngrok.connect(8000).public_url\n",
        "        print(\"=\"*50)\n",
        "        print(f\"\\nüöÄ BRIDGE ONLINE!\\nURL: {public_url}\\n\")\n",
        "        print(\"=\"*50)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERROR: Failed to establish ngrok tunnel: {e}\")\n",
        "        print(\"Please check your NGROK_TOKEN and network connection.\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping server...\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22de08480694474fa057c2eb72ac52c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff783756fd4420aa0c84d30048c9e90",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_29ebb73be9a84e46aa2738e4a1a80f7a",
            "value": "‚Äá291/291‚Äá[01:04&lt;00:00,‚Äá135.73it/s,‚ÄáMaterializing‚Äáparam=model.norm.weight]"
          }
        },
        "282fe5a457b94d10b573ea61f615fe4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbb6e4f7d924442682724d44c8ec91e7",
              "IPY_MODEL_9316dd5f09904484bbcbe7d0e9a11930",
              "IPY_MODEL_22de08480694474fa057c2eb72ac52c8"
            ],
            "layout": "IPY_MODEL_357a48fc1e024da59acfe3f9f94676d2"
          }
        },
        "29ebb73be9a84e46aa2738e4a1a80f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "357a48fc1e024da59acfe3f9f94676d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f63188b8bdc40049976397b867e6782": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6409120291aa4784825078d3ee97dfd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9316dd5f09904484bbcbe7d0e9a11930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6409120291aa4784825078d3ee97dfd5",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f63188b8bdc40049976397b867e6782",
            "value": 291
          }
        },
        "bff783756fd4420aa0c84d30048c9e90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f932540ac5e4434191ba0cb2faa9867e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4d9022f03944e191c3108215528152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb6e4f7d924442682724d44c8ec91e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f932540ac5e4434191ba0cb2faa9867e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fb4d9022f03944e191c3108215528152",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
